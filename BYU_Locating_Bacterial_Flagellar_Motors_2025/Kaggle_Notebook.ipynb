{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\" Train Model \"\"\"\n",
    "model_path = \"/kaggle/input/byu-a-106-yolov8l-daexp-mixupexp/best.pt\"\n",
    "\n",
    "\"\"\" [IMPORTANT]\n",
    "* This parameter has a significant impact on the value of LB since it is the threshold for the prediction score inferred by the model.\n",
    "* In my experiments, 0.5 to 0.55 is optimal for local CV, but when submitting, 0.35 to 0.45 seems to give better results, so there is a difference.\n",
    "\"\"\"\n",
    "CONFIDENCE_THRESHOLD = 0.40\n",
    "\n",
    "MAX_DETECTIONS_PER_TOMO = 3\n",
    "NMS_IOU_THRESHOLD = 0.2\n",
    "CONCENTRATION = 1\n",
    "BATCH_SIZE = 8 "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-04T06:58:10.100976600Z",
     "start_time": "2025-04-04T06:58:10.083871500Z"
    }
   },
   "id": "43ec4927a48bad73",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tar: Error opening archive: Failed to open '/kaggle/input/ultralytics-offlineinstall-yolo12-weights/archive.tar.gz'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: ./packages\n",
      "Requirement already satisfied: ultralytics in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (8.3.26)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from ultralytics) (1.24.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from ultralytics) (3.9.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from ultralytics) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from ultralytics) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from ultralytics) (4.66.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from ultralytics) (2.0.10)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\overr\\anaconda3\\envs\\branchpjh\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"[INFO]\n",
    "* This notebookinstall Ultralytics v8.3.88(2025/03/11 ReleaseVersion)\n",
    "  Can use YOLO12 is latest family version. \n",
    "* If you need a newer version, you can make it available by running and attaching the notebook.\n",
    "  https://www.kaggle.com/code/hideyukizushi/ultralytics-offlineinstall-yolo12-weights\n",
    "\"\"\"\n",
    "!tar xfvz /kaggle/input/ultralytics-offlineinstall-yolo12-weights/archive.tar.gz\n",
    "!pip install --no-index --find-links=./packages ultralytics\n",
    "!rm -rf ./packages"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-04T06:56:32.909316900Z",
     "start_time": "2025-04-04T06:56:31.409616100Z"
    }
   },
   "id": "b9e3cc7b5e5938a9",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "from ultralytics import YOLO\n",
    "import threading\n",
    "import time\n",
    "from contextlib import nullcontext\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-04T06:56:39.460710Z",
     "start_time": "2025-04-04T06:56:36.435301200Z"
    }
   },
   "id": "5db98e70922c6540",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x18dda778f30>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-04T06:56:40.429157500Z",
     "start_time": "2025-04-04T06:56:40.397157800Z"
    }
   },
   "id": "da121dc126c82448",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_path = \"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/\"\n",
    "test_dir = os.path.join(data_path, \"test\")\n",
    "submission_path = \"/kaggle/working/submission.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-04T06:56:43.876505400Z",
     "start_time": "2025-04-04T06:56:43.856493900Z"
    }
   },
   "id": "49e5e6a1545db100",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3090 Ti with 25.76 GB memory\n",
      "Dynamic batch size set to 32 based on 25.76GB free memory\n"
     ]
    }
   ],
   "source": [
    "class GPUProfiler:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.start_time = None\n",
    "        \n",
    "    def __enter__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        self.start_time = time.time()\n",
    "        return self\n",
    "        \n",
    "    def __exit__(self, *args):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        elapsed = time.time() - self.start_time\n",
    "        # print(f\"[PROFILE] {self.name}: {elapsed:.3f}s\")\n",
    "\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "if device.startswith('cuda'):\n",
    "    # Set CUDA optimization flags\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True  # Allow TF32 on Ampere GPUs\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "    # Print GPU info\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert to GB\n",
    "    print(f\"Using GPU: {gpu_name} with {gpu_mem:.2f} GB memory\")\n",
    "    \n",
    "    # Get available GPU memory and set batch size accordingly\n",
    "    free_mem = gpu_mem - torch.cuda.memory_allocated(0) / 1e9\n",
    "    BATCH_SIZE = max(8, min(32, int(free_mem * 4)))  # 4 images per GB as rough estimate\n",
    "    print(f\"Dynamic batch size set to {BATCH_SIZE} based on {free_mem:.2f}GB free memory\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")\n",
    "    BATCH_SIZE = 4  # Reduce batch size for CPU"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-04T06:56:47.026544700Z",
     "start_time": "2025-04-04T06:56:46.981543800Z"
    }
   },
   "id": "7db0f30ee7b70d53",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import threading\n",
    "import time\n",
    "from contextlib import nullcontext\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# 기존 상수 및 변수 선언 등은 그대로 유지\n",
    "CONFIDENCE_THRESHOLD = 0.45  # 탐지 신뢰도 임계값\n",
    "NMS_IOU_THRESHOLD = 0.2       # 3D NMS 임계값\n",
    "CONCENTRATION = 1             # 슬라이스 처리 비율 (빠른 제출용)\n",
    "\n",
    "# 테스트 데이터 경로 및 제출 파일 경로\n",
    "data_path = \"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/\"\n",
    "test_dir = os.path.join(data_path, \"test\")\n",
    "submission_path = \"/kaggle/working/submission.csv\"\n",
    "\n",
    "# 모델 체크포인트 경로 (이제 DETR 모델 체크포인트)\n",
    "model_path = \"/kaggle/input/train-detr/detr_weights/checkpoint.pth\"\n",
    "\n",
    "# GPU 설정\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 8\n",
    "if device.startswith('cuda'):\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"Using GPU: {gpu_name} with {gpu_mem:.2f} GB memory\")\n",
    "    free_mem = gpu_mem - torch.cuda.memory_allocated(0) / 1e9\n",
    "    BATCH_SIZE = max(8, min(32, int(free_mem * 4)))\n",
    "    print(f\"Dynamic batch size set to {BATCH_SIZE} based on {free_mem:.2f}GB free memory\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")\n",
    "    BATCH_SIZE = 4\n",
    "\n",
    "# GPU 프로파일링 컨텍스트 매니저 (변경 없음)\n",
    "class GPUProfiler:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.start_time = None\n",
    "        \n",
    "    def __enter__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        self.start_time = time.time()\n",
    "        return self\n",
    "        \n",
    "    def __exit__(self, *args):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        elapsed = time.time() - self.start_time\n",
    "        print(f\"[PROFILE] {self.name}: {elapsed:.3f}s\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 아래부터 DETR 모델을 YOLO와 유사한 인터페이스로 래핑하는 부분입니다.\n",
    "# YOLO 대신 DETRWrapper를 사용하며 fuse(), to() 메서드도 정의해 나머지 코드 변경 없이 동작하도록 합니다.\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "class Boxes:\n",
    "    def __init__(self, conf, xyxy):\n",
    "        # conf: torch.Tensor, xyxy: torch.Tensor (이미 CPU로 옮겨진 상태)\n",
    "        self.conf = conf.cpu() if conf.is_cuda else conf\n",
    "        self.xyxy = xyxy.cpu() if xyxy.is_cuda else xyxy\n",
    "\n",
    "class Result:\n",
    "    def __init__(self, boxes):\n",
    "        self.boxes = boxes\n",
    "\n",
    "class DETRWrapper:\n",
    "    def __init__(self, model_path):\n",
    "        # DETR 모델 로딩: torch.hub를 이용해 detr_resnet50 모델을 불러오고, 체크포인트로 가중치를 로드\n",
    "        self.model = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=False)\n",
    "        checkpoint = torch.load(model_path, map_location='cpu')\n",
    "        # 체크포인트 파일의 구조에 따라 가중치 로드 (여기서는 checkpoint['model'] 형태라고 가정)\n",
    "        self.model.load_state_dict(checkpoint['model'])\n",
    "        self.model.eval()\n",
    "        self.device = device\n",
    "        self.model.to(device)\n",
    "        # 입력 이미지 전처리 transform (DETR가 기대하는 전처리)\n",
    "        self.transform = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406],\n",
    "                        [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def fuse(self):\n",
    "        # DETR에는 fuse 단계가 없으므로 아무 작업도 하지 않음\n",
    "        pass\n",
    "\n",
    "    def to(self, device):\n",
    "        self.device = device\n",
    "        self.model.to(device)\n",
    "        return self\n",
    "\n",
    "    def __call__(self, image_paths, verbose=False):\n",
    "        results = []\n",
    "        images = []\n",
    "        original_sizes = []\n",
    "        for path in image_paths:\n",
    "            # 이미지를 RGB로 읽고 원본 크기 저장\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            original_sizes.append(img.size)  # (width, height)\n",
    "            images.append(self.transform(img))\n",
    "        batch = torch.stack(images).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(batch)\n",
    "        # outputs: dict with keys 'pred_logits' and 'pred_boxes'\n",
    "        probas = outputs['pred_logits'].softmax(-1)  # (batch_size, num_queries, num_classes+1)\n",
    "        for i in range(batch.shape[0]):\n",
    "            width, height = original_sizes[i]\n",
    "            scores, labels = probas[i].max(-1)  # 각 쿼리의 최대 확률 및 해당 클래스\n",
    "            keep = scores > CONFIDENCE_THRESHOLD\n",
    "            boxes = outputs['pred_boxes'][i]  # (num_queries, 4) in [cx, cy, w, h] (정규화됨)\n",
    "            boxes = self.box_cxcywh_to_xyxy(boxes)\n",
    "            # 이미지 크기에 맞게 스케일 조정\n",
    "            boxes[:, 0] *= width\n",
    "            boxes[:, 1] *= height\n",
    "            boxes[:, 2] *= width\n",
    "            boxes[:, 3] *= height\n",
    "            boxes = boxes[keep]\n",
    "            scores_kept = scores[keep]\n",
    "            results.append(Result(Boxes(scores_kept, boxes)))\n",
    "        return results\n",
    "\n",
    "    def box_cxcywh_to_xyxy(self, x):\n",
    "        # (cx, cy, w, h) -> (x1, y1, x2, y2)\n",
    "        x_c, y_c, w, h = x.unbind(1)\n",
    "        bboxes = torch.stack([x_c - 0.5 * w, y_c - 0.5 * h,\n",
    "                               x_c + 0.5 * w, y_c + 0.5 * h], dim=1)\n",
    "        return bboxes\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 이하 나머지 함수들은 그대로 유지 (YOLO에서 DETR로 모델 변경에 따른 수정 없이 동작)\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def normalize_slice(slice_data):\n",
    "    \"\"\"\n",
    "    Normalize slice data using 2nd and 98th percentiles for better contrast\n",
    "    \"\"\"\n",
    "    p2 = np.percentile(slice_data, 2)\n",
    "    p98 = np.percentile(slice_data, 98)\n",
    "    clipped_data = np.clip(slice_data, p2, p98)\n",
    "    normalized = 255 * (clipped_data - p2) / (p98 - p2)\n",
    "    return np.uint8(normalized)\n",
    "\n",
    "def preload_image_batch(file_paths):\n",
    "    \"\"\"Preload a batch of images to CPU memory\"\"\"\n",
    "    images = []\n",
    "    for path in file_paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            img = np.array(Image.open(path))\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "def process_tomogram(tomo_id, model, index=0, total=1):\n",
    "    \"\"\"\n",
    "    Process a single tomogram and return the most confident motor detection\n",
    "    \"\"\"\n",
    "    tomo_dir = os.path.join(test_dir, tomo_id)\n",
    "    slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n",
    "    \n",
    "    # Apply CONCENTRATION to reduce the number of slices processed\n",
    "    selected_indices = np.linspace(0, len(slice_files)-1, int(len(slice_files) * CONCENTRATION))\n",
    "    selected_indices = np.round(selected_indices).astype(int)\n",
    "    slice_files = [slice_files[i] for i in selected_indices]\n",
    "    \n",
    "    all_detections = []\n",
    "    if device.startswith('cuda'):\n",
    "        streams = [torch.cuda.Stream() for _ in range(min(4, BATCH_SIZE))]\n",
    "    else:\n",
    "        streams = [None]\n",
    "    \n",
    "    next_batch_thread = None\n",
    "    next_batch_images = None\n",
    "    \n",
    "    for batch_start in range(0, len(slice_files), BATCH_SIZE):\n",
    "        if next_batch_thread is not None:\n",
    "            next_batch_thread.join()\n",
    "            next_batch_images = None\n",
    "            \n",
    "        batch_end = min(batch_start + BATCH_SIZE, len(slice_files))\n",
    "        batch_files = slice_files[batch_start:batch_end]\n",
    "        \n",
    "        next_batch_start = batch_end\n",
    "        next_batch_end = min(next_batch_start + BATCH_SIZE, len(slice_files))\n",
    "        next_batch_files = slice_files[next_batch_start:next_batch_end] if next_batch_start < len(slice_files) else []\n",
    "        \n",
    "        if next_batch_files:\n",
    "            next_batch_paths = [os.path.join(tomo_dir, f) for f in next_batch_files]\n",
    "            next_batch_thread = threading.Thread(target=preload_image_batch, args=(next_batch_paths,))\n",
    "            next_batch_thread.start()\n",
    "        else:\n",
    "            next_batch_thread = None\n",
    "        \n",
    "        sub_batches = np.array_split(batch_files, len(streams))\n",
    "        sub_batch_results = []\n",
    "        \n",
    "        for i, sub_batch in enumerate(sub_batches):\n",
    "            if len(sub_batch) == 0:\n",
    "                continue\n",
    "                \n",
    "            stream = streams[i % len(streams)]\n",
    "            with torch.cuda.stream(stream) if stream and device.startswith('cuda') else nullcontext():\n",
    "                sub_batch_paths = [os.path.join(tomo_dir, slice_file) for slice_file in sub_batch]\n",
    "                sub_batch_slice_nums = [int(slice_file.split('_')[1].split('.')[0]) for slice_file in sub_batch]\n",
    "                \n",
    "                with GPUProfiler(f\"Inference batch {i+1}/{len(sub_batches)}\"):\n",
    "                    sub_results = model(sub_batch_paths, verbose=False)\n",
    "                \n",
    "                for j, result in enumerate(sub_results):\n",
    "                    if len(result.boxes.conf) > 0:\n",
    "                        boxes = result.boxes\n",
    "                        for box_idx, confidence in enumerate(boxes.conf):\n",
    "                            if confidence >= CONFIDENCE_THRESHOLD:\n",
    "                                x1, y1, x2, y2 = boxes.xyxy[box_idx].cpu().numpy()\n",
    "                                x_center = (x1 + x2) / 2\n",
    "                                y_center = (y1 + y2) / 2\n",
    "                                all_detections.append({\n",
    "                                    'z': round(sub_batch_slice_nums[j]),\n",
    "                                    'y': round(y_center),\n",
    "                                    'x': round(x_center),\n",
    "                                    'confidence': float(confidence)\n",
    "                                })\n",
    "        \n",
    "        if device.startswith('cuda'):\n",
    "            torch.cuda.synchronize()\n",
    "    \n",
    "    if next_batch_thread is not None:\n",
    "        next_batch_thread.join()\n",
    "    \n",
    "    final_detections = perform_3d_nms(all_detections, NMS_IOU_THRESHOLD)\n",
    "    final_detections.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "    \n",
    "    if not final_detections:\n",
    "        return {\n",
    "            'tomo_id': tomo_id,\n",
    "            'Motor axis 0': -1,\n",
    "            'Motor axis 1': -1,\n",
    "            'Motor axis 2': -1\n",
    "        }\n",
    "    \n",
    "    best_detection = final_detections[0]\n",
    "    return {\n",
    "        'tomo_id': tomo_id,\n",
    "        'Motor axis 0': round(best_detection['z']),\n",
    "        'Motor axis 1': round(best_detection['y']),\n",
    "        'Motor axis 2': round(best_detection['x'])\n",
    "    }\n",
    "\n",
    "def perform_3d_nms(detections, iou_threshold):\n",
    "    \"\"\"\n",
    "    Perform 3D Non-Maximum Suppression on detections to merge nearby motors\n",
    "    \"\"\"\n",
    "    if not detections:\n",
    "        return []\n",
    "    \n",
    "    detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n",
    "    final_detections = []\n",
    "    \n",
    "    def distance_3d(d1, d2):\n",
    "        return np.sqrt((d1['z'] - d2['z'])**2 + \n",
    "                       (d1['y'] - d2['y'])**2 + \n",
    "                       (d1['x'] - d2['x'])**2)\n",
    "    \n",
    "    box_size = 24\n",
    "    distance_threshold = box_size * iou_threshold\n",
    "    \n",
    "    while detections:\n",
    "        best_detection = detections.pop(0)\n",
    "        final_detections.append(best_detection)\n",
    "        detections = [d for d in detections if distance_3d(d, best_detection) > distance_threshold]\n",
    "    \n",
    "    return final_detections\n",
    "\n",
    "def debug_image_loading(tomo_id):\n",
    "    \"\"\"\n",
    "    Debug function to check image loading\n",
    "    \"\"\"\n",
    "    tomo_dir = os.path.join(test_dir, tomo_id)\n",
    "    slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n",
    "    \n",
    "    if not slice_files:\n",
    "        print(f\"No image files found in {tomo_dir}\")\n",
    "        return\n",
    "        \n",
    "    sample_file = slice_files[len(slice_files)//2]\n",
    "    img_path = os.path.join(tomo_dir, sample_file)\n",
    "    \n",
    "    try:\n",
    "        img_pil = Image.open(img_path)\n",
    "        img_array_pil = np.array(img_pil)\n",
    "        img_cv2 = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_rgb = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {img_path}: {e}\")\n",
    "        \n",
    "    try:\n",
    "        test_model = DETRWrapper(model_path)\n",
    "        test_results = test_model([img_path], verbose=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error with DETR processing: {e}\")\n",
    "\n",
    "def generate_submission():\n",
    "    \"\"\"\n",
    "    Main function to generate the submission file\n",
    "    \"\"\"\n",
    "    test_tomos = sorted([d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))])\n",
    "    total_tomos = len(test_tomos)\n",
    "    \n",
    "    if test_tomos:\n",
    "        debug_image_loading(test_tomos[0])\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # DETRWrapper를 사용하여 모델을 로드 (나머지 코드는 그대로 유지)\n",
    "    model = DETRWrapper(model_path)\n",
    "    model.to(device)\n",
    "    \n",
    "    if device.startswith('cuda'):\n",
    "        model.fuse()\n",
    "        if torch.cuda.get_device_capability(0)[0] >= 7:\n",
    "            # DETR에서는 half precision 적용이 별도 처리 필요하므로 생략하거나 추가 구현 필요\n",
    "            pass\n",
    "    \n",
    "    results = []\n",
    "    motors_found = 0\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        future_to_tomo = {}\n",
    "        \n",
    "        for i, tomo_id in enumerate(test_tomos, 1):\n",
    "            future = executor.submit(process_tomogram, tomo_id, model, i, total_tomos)\n",
    "            future_to_tomo[future] = tomo_id\n",
    "        \n",
    "        for future in future_to_tomo:\n",
    "            tomo_id = future_to_tomo[future]\n",
    "            try:\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "                \n",
    "                has_motor = not pd.isna(result['Motor axis 0'])\n",
    "                if has_motor:\n",
    "                    motors_found += 1\n",
    "                    print(f\"Motor found in {tomo_id} at position: \"\n",
    "                          f\"z={result['Motor axis 0']}, y={result['Motor axis 1']}, x={result['Motor axis 2']}\")\n",
    "                else:\n",
    "                    print(f\"No motor detected in {tomo_id}\")\n",
    "                    \n",
    "                print(f\"Current detection rate: {motors_found}/{len(results)} ({motors_found/len(results)*100:.1f}%)\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {tomo_id}: {e}\")\n",
    "                results.append({\n",
    "                    'tomo_id': tomo_id,\n",
    "                    'Motor axis 0': -1,\n",
    "                    'Motor axis 1': -1,\n",
    "                    'Motor axis 2': -1\n",
    "                })\n",
    "    \n",
    "    submission_df = pd.DataFrame(results)\n",
    "    submission_df = submission_df[['tomo_id', 'Motor axis 0', 'Motor axis 1', 'Motor axis 2']]\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(\"=\"*50)\n",
    "    print(\"= Submission preview:\")\n",
    "    print(\"=\"*50)\n",
    "    print(submission_df.head())\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    submission = generate_submission()\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nTotal execution time: {elapsed:.2f} seconds ({elapsed/60:.2f} minutes)\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "745aef3553ea246f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
